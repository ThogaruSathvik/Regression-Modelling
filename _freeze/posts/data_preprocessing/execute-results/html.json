{
  "hash": "2420cf3393fa17333df8245940f4e2ee",
  "result": {
    "markdown": "---\ntitle: \"Data PreProcessing\"\nauthor: \"Sathvik Thogaru\"\ndate: \"08/02/2022\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\n---\n\n\n\n\n# Libraries\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(dplyr)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'dplyr'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n:::\n\n```{.r .cell-code}\nlibrary(tidyr)\nlibrary(plotly)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'plotly'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:stats':\n\n    filter\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:graphics':\n\n    layout\n```\n:::\n\n```{.r .cell-code}\nlibrary(readxl)\n```\n:::\n\n\n# Load datasets\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_149_with_Duans <- read_excel(\"_data/n=149 with Duans.xlsx\")\nX091522_LABWORKS_DOWNLOAD <- read_excel(\"_data/091522 LABWORKS DOWNLOAD.xlsx\")\n```\n:::\n\n\n\nHad a problem while loading the data.`guess_max` determines how many cells in each column are used to make a guess of the column type. we can provide a `guess_max`  for read_excel to correctly guess the column type. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npearson_data <- read_excel(\"_data/1 of 3 - USGS gage data downloaded 092022.xlsx\", \n    sheet = \"Pearson\", guess_max = 1048576)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(n_149_with_Duans)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 9\n  datetime             TURB ECOLI arith…¹ predi…²     SD neg S…³ 1.96 …⁴ neg 1…⁵\n  <dttm>              <dbl> <dbl>   <dbl>   <dbl>  <dbl>   <dbl>   <dbl>   <dbl>\n1 2019-05-22 10:00:00   3     130    45.9    55.7   85.8    24.6    156.    13.5\n2 2019-05-29 09:45:00   3      77    45.9    55.7   85.8    24.6    156.    13.5\n3 2019-06-05 08:00:00   3.7    50    59.9    72.7  112.     32.1    204.    17.6\n4 2019-06-12 10:00:00  19.9   488   505.    613.   943.    270.    1719.   148. \n5 2019-06-19 08:00:00  69    2685  2442.   2965.  4561.   1307.    8310.   717. \n6 2019-06-19 10:15:00  58.9  1990  1998.   2426.  3732.   1069.    6800.   587. \n# … with abbreviated variable names ¹​`arithmetic - Predicted ECOLI`,\n#   ²​`predicted ecoli with Duans smearing adjustment`, ³​`neg SD`, ⁴​`1.96 SD`,\n#   ⁵​`neg 1.96 SD`\n```\n:::\n\n```{.r .cell-code}\nhead(pearson_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 23\n  agency_cd Name   site_no datetime            tz_cd    pH pH-st…¹    DO DO-st…²\n  <chr>     <chr>    <dbl> <dttm>              <chr> <dbl> <chr>   <dbl> <chr>  \n1 USGS      Pears… 3451500 2019-03-01 00:00:00 EST      NA <NA>       NA <NA>   \n2 USGS      Pears… 3451500 2019-03-01 00:15:00 EST      NA <NA>       NA <NA>   \n3 USGS      Pears… 3451500 2019-03-01 00:30:00 EST      NA <NA>       NA <NA>   \n4 USGS      Pears… 3451500 2019-03-01 00:45:00 EST      NA <NA>       NA <NA>   \n5 USGS      Pears… 3451500 2019-03-01 01:00:00 EST      NA <NA>       NA <NA>   \n6 USGS      Pears… 3451500 2019-03-01 01:15:00 EST      NA <NA>       NA <NA>   \n# … with 14 more variables: SC <dbl>, `SC-status` <chr>, Turb_FNU <dbl>,\n#   `Turb-status` <chr>, WL_Elev <dbl>, `WL_Elev-status` <chr>, Temp_C <dbl>,\n#   `Temp-status` <chr>, Q_cfs <dbl>, `Q-status` <chr>, Stage_ft <dbl>,\n#   `Stage - status` <chr>, Precip_in <dbl>, `Precip-status` <chr>, and\n#   abbreviated variable names ¹​`pH-status`, ²​`DO-status`\n# ℹ Use `colnames()` to see all variable names\n```\n:::\n:::\n\n\n## finding the datetime column class in the datasets\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclass(n_149_with_Duans$datetime)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"POSIXct\" \"POSIXt\" \n```\n:::\n\n```{.r .cell-code}\nclass(pearson_data$datetime)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"POSIXct\" \"POSIXt\" \n```\n:::\n:::\n\nBoth the datetime columns in the datsets are of the **\"POSIXct\" \"POSIXt\"** class\n\n## finding the range of the datetime column for datasets\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrange(n_149_with_Duans$datetime)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"2019-05-22 10:00:00 UTC\" \"2021-10-11 09:55:00 UTC\"\n```\n:::\n:::\n\n\n`n_149_with_Duans` has the data between time period  **2019-05-22 10:00:00 UTC - 2021-10-11 09:55:00 UTC**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrange(pearson_data$datetime)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"2019-03-01 00:00:00 UTC\" \"2022-09-20 10:30:00 UTC\"\n```\n:::\n:::\n\n\n`pearson_data` has the data data between time period  **2019-03-01 00:00:00 UTC - 2022-09-20 10:30:00 UTC**\n\nRestricting the pearson data in between time range of `n_149_with_Duans` i.e., **2019-05-22 10:00:00 UTC - 2021-10-11 09:55:00 UTC** since we have the Ecoli values for this range of data\n\n\n::: {.cell}\n\n```{.r .cell-code}\npearson_data <- pearson_data[pearson_data$datetime >= min(n_149_with_Duans$datetime)\n                             & pearson_data$datetime <= max(n_149_with_Duans$datetime),]\n```\n:::\n\n\n\nWhen found the lag between the time periods of each observation, the lag varies differently between the time periods for `n_149_with_Duans` but is constant for `pearson_data` which is **900** secs\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(pearson_data$datetime - lag(pearson_data$datetime), ylim = c(0,1000), ylab = \"time lag between two observations\", main = \"pearson_data\")\n```\n\n::: {.cell-output-display}\n![](data_preprocessing_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(n_149_with_Duans$datetime - lag(n_149_with_Duans$datetime), ylim = c(0,1000), ylab = \"time lag between two observations\", main = \"n_149_with_Duans\")\n```\n\n::: {.cell-output-display}\n![](data_preprocessing_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\nConsidering only the observations that are in the n_149_with_Duans, merging the `pearson_data` and `n_149_with_Duans`by datetime and keeping all the values in `n_149_with_Duans`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmerged_data <- merge(pearson_data,n_149_with_Duans, by = \"datetime\", all.y = TRUE)\n```\n:::\n\n\nsplitting the datetime column into `Year`, `month`, `day`, and `time` for future data analysis\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmerged_data$Date <- as.Date(merged_data$datetime)\nmerged_data <- merged_data %>% \n  tidyr::separate(\"Date\", c(\"Year\", \"Month\", \"Day\"), sep = \"-\")\n\nmerged_data$Time <- format(merged_data$datetime,\"%H:%M:%S\")\n```\n:::\n",
    "supporting": [
      "data_preprocessing_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}