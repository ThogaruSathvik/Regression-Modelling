[
  {
    "objectID": "posts/data_preprocessing.html",
    "href": "posts/data_preprocessing.html",
    "title": "Data Preprocessing",
    "section": "",
    "text": "Code\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(tidyr)\nlibrary(tidyverse)\n\n\n── Attaching packages\n───────────────────────────────────────\ntidyverse 1.3.2 ──\n\n\n✔ tibble  3.1.8     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n✔ purrr   0.3.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()"
  },
  {
    "objectID": "posts/data_preprocessing.html#load-datasets",
    "href": "posts/data_preprocessing.html#load-datasets",
    "title": "Data Preprocessing",
    "section": "Load datasets",
    "text": "Load datasets\n\n\nCode\nn_149_with_Duans <- read_excel(\"_data/n=149 with Duans.xlsx\")\nX091522_LABWORKS_DOWNLOAD <- read_excel(\"_data/091522 LABWORKS DOWNLOAD.xlsx\")\n\nn_149_with_Duans\n\n\n\n\n  \n\n\n\nHad a problem while loading the data.guess_max determines how many cells in each column are used to make a guess of the column type. we can provide a guess_max for read_excel to correctly guess the column type.\n\n\nCode\npearson_data <- read_excel(\"_data/1 of 3 - USGS gage data downloaded 092022.xlsx\", \n    sheet = \"Pearson\", guess_max = 1048576)\n\npearson_data"
  },
  {
    "objectID": "posts/data_preprocessing.html#finding-the-datetime-column-class-in-the-datasets",
    "href": "posts/data_preprocessing.html#finding-the-datetime-column-class-in-the-datasets",
    "title": "Data Preprocessing",
    "section": "finding the datetime column class in the datasets",
    "text": "finding the datetime column class in the datasets\n\n\nCode\nclass(n_149_with_Duans$datetime)\n\n\n[1] \"POSIXct\" \"POSIXt\" \n\n\nCode\nclass(pearson_data$datetime)\n\n\n[1] \"POSIXct\" \"POSIXt\" \n\n\nBoth the datetime columns in the datsets are of the \"POSIXct\" \"POSIXt\" class"
  },
  {
    "objectID": "posts/data_preprocessing.html#finding-the-range-of-the-datetime-column-for-datasets",
    "href": "posts/data_preprocessing.html#finding-the-range-of-the-datetime-column-for-datasets",
    "title": "Data Preprocessing",
    "section": "finding the range of the datetime column for datasets",
    "text": "finding the range of the datetime column for datasets\n\n\nCode\nrange(n_149_with_Duans$datetime)\n\n\n[1] \"2019-05-22 10:00:00 UTC\" \"2021-10-11 09:55:00 UTC\"\n\n\nn_149_with_Duans has the data between time period 2019-05-22 10:00:00 UTC - 2021-10-11 09:55:00 UTC\n\n\nCode\nrange(pearson_data$datetime)\n\n\n[1] \"2019-03-01 00:00:00 UTC\" \"2022-09-20 10:30:00 UTC\"\n\n\npearson_data has the data data between time period 2019-03-01 00:00:00 UTC to 2022-09-20 10:30:00 UTC\nRestricting the pearson data in between time range of n_149_with_Duans i.e., 2019-05-22 10:00:00 UTC - 2021-10-11 09:55:00 UTC since we have the Ecoli values for this range of data\n\n\nCode\npearson_data <- pearson_data[pearson_data$datetime >= min(n_149_with_Duans$datetime)\n                             & pearson_data$datetime <= max(n_149_with_Duans$datetime),]\n\n\nWhen found the lag between the time periods of each observation, the lag varies differently between the time periods for n_149_with_Duans but is constant for pearson_data which is 900 secs\n\n\nCode\nplot(pearson_data$datetime - lag(pearson_data$datetime), ylim = c(0,1000), ylab = \"time lag between two observations\", main = \"pearson_data\")\n\n\n\n\n\n\n\nCode\nplot(n_149_with_Duans$datetime - lag(n_149_with_Duans$datetime), ylim = c(0,1000), ylab = \"time lag between two observations\", main = \"n_149_with_Duans\")\n\n\n\n\n\nConsidering only the observations that are in the n_149_with_Duans, merging the pearson_data and n_149_with_Duansby datetime and keeping all the values in n_149_with_Duans\n\n\nCode\nmerged_data <- merge(pearson_data,n_149_with_Duans, by = \"datetime\", all.y = TRUE)\n\n\nsplitting the datetime column into Year, month, day, and time for future data analysis"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Regression Modelling Project",
    "section": "",
    "text": "Data Preprocessing\n\n\n\n\n\n\n\ndata preprocessing\n\n\n\n\n\n\n\n\n\n\n\nOct 9, 2022\n\n\nSathvik\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Contributors",
    "section": "",
    "text": "Ning Duan\nSaid Arslan\nSathvik Thogaru\nThomas Robacker"
  },
  {
    "objectID": "posts/data_preprocessing.html#merged-data",
    "href": "posts/data_preprocessing.html#merged-data",
    "title": "Data Preprocessing",
    "section": "Merged Data",
    "text": "Merged Data\n\n\nCode\nmerged_data$Date <- as.Date(merged_data$datetime)\nmerged_data <- merged_data %>% \n  tidyr::separate(\"Date\", c(\"Year\", \"Month\", \"Day\"), sep = \"-\")\n\nmerged_data$Time <- format(merged_data$datetime,\"%H:%M:%S\")\n\nmerged_data"
  }
]